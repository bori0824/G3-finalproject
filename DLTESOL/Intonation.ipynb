{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bori0824/G3-finalproject/blob/main/DLTESOL/Intonation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intonation contour: visible intonation (pitch track)"
      ],
      "metadata": {
        "id": "PiOwHuIhmfUn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-mB6lyMyFr5",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ðŸ“Œ Run this code before you start\n",
        "%%capture\n",
        "!pip install pyqrcode gradio pandas gtts requests librosa matplotlib pydub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Generate speech and show intonation\n",
        "from gtts import gTTS\n",
        "from pydub import AudioSegment\n",
        "from io import BytesIO\n",
        "from IPython.display import Audio\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Function to generate and save a WAV file\n",
        "def generate_and_save_wav(word, filename='output.wav'):\n",
        "    tts = gTTS(text=word, lang='en')\n",
        "    mp3_fp = BytesIO()\n",
        "    tts.write_to_fp(mp3_fp)\n",
        "    mp3_fp.seek(0)\n",
        "    sound = AudioSegment.from_file(mp3_fp, format=\"mp3\")\n",
        "    sound.export(filename, format=\"wav\")\n",
        "    return filename\n",
        "\n",
        "# Function to extract and plot the pitch contour\n",
        "def plot_pitch_contour(audio_file_path):\n",
        "    y, sr = librosa.load(audio_file_path, sr=None)\n",
        "    fmin = librosa.note_to_hz('C2')\n",
        "    fmax = librosa.note_to_hz('C6')\n",
        "    pitch, voiced_flag, voiced_probs = librosa.pyin(y, fmin=fmin, fmax=fmax, sr=sr)\n",
        "    pitch[~np.isfinite(pitch)] = 0\n",
        "\n",
        "    plt.figure(figsize=(14, 5))\n",
        "    librosa.display.waveshow(y, sr=sr)\n",
        "    times = librosa.times_like(pitch, sr=sr)\n",
        "    for i in range(len(pitch)):\n",
        "        if pitch[i] > 0:\n",
        "            plt.plot(times[i], pitch[i], 'ro')\n",
        "\n",
        "    plt.title('Pitch Contour')\n",
        "    plt.xlabel('Time (s)')\n",
        "    plt.ylabel('Pitch (Hz)')\n",
        "    plt.ylim(0, 350)\n",
        "    plt.show()\n",
        "\n",
        "# Get user input\n",
        "mytext = input('Type a word or sentence: ')\n",
        "\n",
        "# Generate speech and save to a WAV file\n",
        "audio_file = generate_and_save_wav(mytext)\n",
        "\n",
        "# Play the audio\n",
        "print(f\"Generated speech for: {mytext}\")\n",
        "Audio(audio_file)\n",
        "\n",
        "# Display the pitch contour\n",
        "print(f\"Pitch contour for: {mytext}\")\n",
        "plot_pitch_contour(audio_file)\n"
      ],
      "metadata": {
        "id": "UalGmYflpNUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio"
      ],
      "metadata": {
        "id": "CwJ6pRnrPJDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "pBE2B0qWPKQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from gtts import gTTS\n",
        "from pydub import AudioSegment\n",
        "from io import BytesIO\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def generate_and_save_wav(word):\n",
        "    tts = gTTS(text=word, lang='en')\n",
        "    mp3_fp = BytesIO()\n",
        "    tts.write_to_fp(mp3_fp)\n",
        "    mp3_fp.seek(0)\n",
        "    sound = AudioSegment.from_file(mp3_fp, format=\"mp3\")\n",
        "    buffer = BytesIO()\n",
        "    sound.export(buffer, format=\"wav\")\n",
        "    buffer.seek(0)\n",
        "    return buffer.read()  # Return the bytes of the audio file\n",
        "\n",
        "def plot_pitch_contour(word):\n",
        "    audio_bytes = generate_and_save_wav(word)\n",
        "    audio_buffer = BytesIO(audio_bytes)\n",
        "    y, sr = librosa.load(audio_buffer, sr=None)\n",
        "    fmin = librosa.note_to_hz('C2')\n",
        "    fmax = librosa.note_to_hz('C6')\n",
        "    pitch, voiced_flag, voiced_probs = librosa.pyin(y, fmin=fmin, fmax=fmax, sr=sr)\n",
        "    pitch[~np.isfinite(pitch)] = 0\n",
        "\n",
        "    plt.figure(figsize=(14, 5))\n",
        "    librosa.display.waveshow(y, sr=sr)\n",
        "    times = librosa.times_like(pitch, sr=sr)\n",
        "    plt.scatter(times, pitch, color='red', s=1)  # Use scatter for better visualization\n",
        "\n",
        "    plt.title('Pitch Contour')\n",
        "    plt.xlabel('Time (s)')\n",
        "    plt.ylabel('Pitch (Hz)')\n",
        "    plt.ylim(0, 350)\n",
        "\n",
        "    buf = BytesIO()\n",
        "    plt.savefig(buf, format=\"png\")\n",
        "    plt.close()\n",
        "    buf.seek(0)\n",
        "\n",
        "    img = Image.open(buf)\n",
        "    img_array = np.array(img)\n",
        "    return img_array  # Return numpy array directly usable by Gradio\n",
        "\n",
        "def process_text(word):\n",
        "    audio_bytes = generate_and_save_wav(word)\n",
        "    plot_img_array = plot_pitch_contour(word)\n",
        "    return audio_bytes, plot_img_array\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=process_text,\n",
        "    inputs=\"text\",\n",
        "    outputs=[\"audio\", \"image\"],\n",
        "    title=\"Speech Synthesis and Intonation Display\",\n",
        "    description=\"Type a word or sentence to generate speech and visualize the intonation pitch contour.\"\n",
        ")\n",
        "\n",
        "# iface.launch()\n",
        "\n",
        "iface.launch(debug=True)"
      ],
      "metadata": {
        "id": "OXVC8qtSPMEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import matplotlib\n",
        "import numpy\n",
        "print(\"Librosa:\", librosa.__version__)\n",
        "print(\"Matplotlib:\", matplotlib.__version__)\n",
        "print(\"NumPy:\", numpy.__version__)\n"
      ],
      "metadata": {
        "id": "Ek053rYze12H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the code on huggingface (2024.0417)"
      ],
      "metadata": {
        "id": "0326ozTcjJmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from gtts import gTTS\n",
        "from pydub import AudioSegment\n",
        "from io import BytesIO\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')  # Set the backend to 'Agg' for non-GUI environments\n",
        "\n",
        "\n",
        "def generate_and_save_wav(word):\n",
        "    tts = gTTS(text=word, lang='en')\n",
        "    mp3_fp = BytesIO()\n",
        "    tts.write_to_fp(mp3_fp)\n",
        "    mp3_fp.seek(0)\n",
        "    sound = AudioSegment.from_file(mp3_fp, format=\"mp3\")\n",
        "    buffer = BytesIO()\n",
        "    sound.export(buffer, format=\"wav\")\n",
        "    buffer.seek(0)\n",
        "    return buffer.read()  # Return the bytes of the audio file\n",
        "\n",
        "def plot_pitch_contour(word):\n",
        "    audio_bytes = generate_and_save_wav(word)\n",
        "    audio_buffer = BytesIO(audio_bytes)\n",
        "    y, sr = librosa.load(audio_buffer, sr=None)\n",
        "    fmin = librosa.note_to_hz('C2')\n",
        "    fmax = librosa.note_to_hz('C6')\n",
        "    pitch, voiced_flag, voiced_probs = librosa.pyin(y, fmin=fmin, fmax=fmax, sr=sr)\n",
        "    pitch[~np.isfinite(pitch)] = 0\n",
        "\n",
        "    plt.figure(figsize=(14, 5))\n",
        "    librosa.display.waveshow(y, sr=sr)\n",
        "    times = librosa.times_like(pitch, sr=sr)\n",
        "    plt.scatter(times, pitch, color='red', s=1)  # Use scatter for better visualization\n",
        "\n",
        "    plt.title('Pitch Contour')\n",
        "    plt.xlabel('Time (s)')\n",
        "    plt.ylabel('Pitch (Hz)')\n",
        "    plt.ylim(0, 350)\n",
        "\n",
        "    buf = BytesIO()\n",
        "    plt.savefig(buf, format=\"png\")\n",
        "    plt.close()\n",
        "    buf.seek(0)\n",
        "\n",
        "    img = Image.open(buf)\n",
        "    img_array = np.array(img)\n",
        "    return img_array  # Return numpy array directly usable by Gradio\n",
        "\n",
        "def process_text(word):\n",
        "    audio_bytes = generate_and_save_wav(word)\n",
        "    plot_img_array = plot_pitch_contour(word)\n",
        "    return audio_bytes, plot_img_array\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=process_text,\n",
        "    inputs=\"text\",\n",
        "    outputs=[\"audio\", \"image\"],\n",
        "    title=\"Speech Synthesis and Intonation Display\",\n",
        "    description=\"Type a word or sentence to generate speech and visualize the intonation pitch contour.\"\n",
        ")\n",
        "\n",
        "# iface.launch()\n",
        "\n",
        "iface.launch(debug=True)"
      ],
      "metadata": {
        "id": "qyqQbiOrhYA-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}